(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{551:function(t,e,a){t.exports=a.p+"assets/img/executor-cpu-before.82fa6c91.png"},552:function(t,e,a){t.exports=a.p+"assets/img/executor-cpu-after.f9cc51de.png"},553:function(t,e,a){t.exports=a.p+"assets/img/lag-before.8249164c.png"},554:function(t,e,a){t.exports=a.p+"assets/img/lag-after.bbf4e884.png"},555:function(t,e,a){t.exports=a.p+"assets/img/queue-before.3153f882.png"},556:function(t,e,a){t.exports=a.p+"assets/img/queue-after.77035928.png"},557:function(t,e,a){t.exports=a.p+"assets/img/executor-duration-before.5f06143d.png"},558:function(t,e,a){t.exports=a.p+"assets/img/executor-duration-after.2798da95.png"},559:function(t,e,a){t.exports=a.p+"assets/media/deps.b59b5e10.mp4"},560:function(t,e,a){t.exports=a.p+"assets/img/deps.90668f87.png"},629:function(t,e,a){"use strict";a.r(e);var s=a(19),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("p",[t._v("Since our "),s("a",{attrs:{href:"./2022-02-01-kestra-opensource"}},[t._v("public launch")]),t._v(", we have made a lot of works to give you the better experience we expect with Kestra. This version brings a lot of performance enhancement in order to provide the smooth experience with large clusters and some others cool features.")]),t._v(" "),s("h2",{attrs:{id:"performance-for-large-clusters"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#performance-for-large-clusters"}},[t._v("#")]),t._v(" Performance for large clusters")]),t._v(" "),s("p",[t._v("Since we have already a "),s("a",{attrs:{href:"./2022-02-22-leroy-merlin-usage-kestra"}},[t._v("large deployment")]),t._v(" at Leroy Merlin, we have hit many times some performance issue, but this one was more complicated to find. Here you will expose you some metrics based on our large deployment on production environment for "),s("a",{attrs:{href:"./2022-02-22-leroy-merlin-usage-kestra"}},[t._v("Leroy Merlin")]),t._v(" and will show you charts before and after the changes for the same workload. Leroy Merlin usage is mostly processed during the night, all flows starting at the same time near 3AM.")]),t._v(" "),s("p",[t._v("We have made a hard work "),s("strong",[t._v("reduce cpu usage and latency")]),t._v(".")]),t._v(" "),s("p",[t._v("As you can see, the same workload use 3 executors before (we used autoscaling) before, with a total cpu usage of 2.5 cores for more than 6 hours."),s("br"),t._v("\nAfter, we are mostly "),s("strong",[t._v("used 0.5 cores")]),t._v(" with a peek at 1.5 core only for 1 hours, all the workload handle by only 2 executors (minimum of autoscaling).")]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(551),alt:"before"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("Before")])]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(552),alt:"after"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("After")])]),t._v(" "),s("p",[t._v("For the kafka side, we have also "),s("strong",[t._v("improved the latency")]),t._v("."),s("br"),t._v("\nWe have a lot of "),s("RouterLink",{attrs:{to:"/docs/developer-guide/triggers/flow.html"}},[t._v("flow triggers")]),t._v(", that need to be analysed for each execution ended. When you have high volume execution, a lot of message is send through Kafka and if your consumer is too slow, the queue is filling and increase latency."),s("br"),t._v("\nBefore, we have a large accumulation of message that lead to late start of flow executions (few minutes). The optimisation let us keep flow start few seconds after.")],1),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(553),alt:"before"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("Before")])]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(554),alt:"after"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("After")])]),t._v(" "),s("p",[t._v("The last charts is showing the delay between the task creation and the task started by worker. As we optimized the Kafka processing globally, we avoid to enqueue message on kafka and reduce the delay between creation of the task and processing by workers.")]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(555),alt:"before"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("Before")])]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(556),alt:"after"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("After")])]),t._v(" "),s("p",[t._v("All these improvements also offer a "),s("strong",[t._v("large reduction on total duration")]),t._v(" of execution.  All message being consumed quickly, the delay between each task is reduced and will reduce the total duration of the execution.")]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(557),alt:"before"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("Before")])]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(558),alt:"after"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("After")])]),t._v(" "),s("p",[t._v("Keep in mind, that Leroy Merlin workflow is unbalanced, and all the executions is staring at the same time, with 3000+ executions & 35,000+ tasks in a short time, 50% of the workload of the whole day. We need to provide the same exigence for night processing even if we are all sleep."),s("br"),t._v("\nWe have some other optimizations in the backlog, but we have made a great improvement right now that will handle more complex cluster with a lot of flow & concurrent executions. A full blog post is coming to expose what we have discovered scaling a "),s("a",{attrs:{href:"https://kafka.apache.org/documentation/streams/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kafka Streams"),s("OutboundLink")],1),t._v(" application.")]),t._v(" "),s("h2",{attrs:{id:"resilience"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#resilience"}},[t._v("#")]),t._v(" Resilience")]),t._v(" "),s("p",[t._v("We rely on kestra internal storage for data passed between tasks,")]),t._v(" "),s("h2",{attrs:{id:"new-plugins-improvement"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#new-plugins-improvement"}},[t._v("#")]),t._v(" New plugins & improvement")]),t._v(" "),s("h3",{attrs:{id:"jdbc-plugins"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#jdbc-plugins"}},[t._v("#")]),t._v(" JDBC plugins")]),t._v(" "),s("h4",{attrs:{id:"batch-query"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#batch-query"}},[t._v("#")]),t._v(" Batch query")]),t._v(" "),s("p",[t._v("Jdbc plugins have a major update allowing to bulk request. This allows you to use any Kestra storage generated files in order to generate a batch request."),s("br"),t._v("\nNow you can read data from any task and generate a bulk request in order to insert or update data on most jdbc database."),s("br"),t._v("\nLook at this example:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tasks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" query\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"io.kestra.plugin.jdbc.mysql.Query"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" jdbc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("mysql"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//127.0.0.1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("56982/\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("username")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" mysql_user\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("password")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" mysql_passwd\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sql")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" select * from users\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("store")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" load\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"io.kestra.plugin.jdbc.sqlserver.Batch"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" jdbc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("sqlserver"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//localhost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("41433;trustServerCertificate=true\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("username")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sa\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("password")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Sqls3rv3r_Pa55word"),s("span",{pre:!0,attrs:{class:"token tag"}},[t._v("!")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("from")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ inputs.query.uri }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sql")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into users values( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )"')]),t._v("\n")])])]),s("p",[t._v("We read a from a mysql database table using a "),s("RouterLink",{attrs:{to:"/plugins/plugin-jdbc-mysql/tasks/io.kestra.plugin.jdbc.mysql.Query.html"}},[t._v("Query")]),t._v(" and store it on internal storage, after that, we generate a "),s("RouterLink",{attrs:{to:"/plugins/plugin-jdbc-sqlserver/tasks/io.kestra.plugin.jdbc.sqlserver.Batch.html"}},[t._v("bulk insert")]),t._v(" that will load the resulting dataset to a Microsoft SQL Server database.")],1),t._v(" "),s("div",{staticClass:"custom-block success"},[s("p",{staticClass:"custom-block-title"},[t._v("Move data to jdbc easily")]),t._v(" "),s("p",[t._v("As we rely on internal storage of Kestra, any task that produce internal kestra storage like "),s("RouterLink",{attrs:{to:"/plugins/plugin-serdes/tasks/json/io.kestra.plugin.serdes.json.JsonReader.html"}},[t._v("JsonReader")]),t._v(", "),s("RouterLink",{attrs:{to:"/plugins/plugin-serdes/tasks/avro/io.kestra.plugin.serdes.avro.AvroReader.html"}},[t._v("AvroReader")]),t._v(", ... can be used as source. You can now move data from any source and any format thanks to Kestra plugins.")],1)]),t._v(" "),s("h4",{attrs:{id:"new-jdbc-plugin"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#new-jdbc-plugin"}},[t._v("#")]),t._v(" New Jdbc plugin")]),t._v(" "),s("p",[t._v("We also introduce 2 new jdbc plugins :")]),t._v(" "),s("ul",[s("li",[s("RouterLink",{attrs:{to:"/plugins/plugin-jdbc-sqlserver/"}},[t._v("Microsoft SQL Server")])],1),t._v(" "),s("li",[s("RouterLink",{attrs:{to:"/plugins/plugin-jdbc-vectorwise/"}},[t._v("Actian Vectorwise")])],1)]),t._v(" "),s("p",[t._v("Both support Query & Batch query enabling you to imagine a lot more use cases.")]),t._v(" "),s("h2",{attrs:{id:"kafka"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#kafka"}},[t._v("#")]),t._v(" Kafka")]),t._v(" "),s("p",[t._v("Kafka plugins was also release with a first task "),s("RouterLink",{attrs:{to:"/plugins/plugin-kafka/tasks/io.kestra.plugin.kafka.Produce.html"}},[t._v("Produce")]),t._v(" (Consume will come soon). Like other plugins jdbc, json, csv, ..., Kafka plugins rely on Kestra internal storage, allowing you to send from any source to Kafka.")],1),t._v(" "),s("p",[t._v("We support for now many "),s("RouterLink",{attrs:{to:"/plugins/plugin-kafka/tasks/io.kestra.plugin.kafka.Produce.html#valueserializer"}},[t._v("types of serializer inside Kafka")]),t._v(" but most notable are "),s("code",[t._v("STRING")]),t._v(", "),s("code",[t._v("JSON")]),t._v(" & "),s("code",[t._v("AVRO")]),t._v(" with support with "),s("a",{attrs:{href:"https://docs.confluent.io/platform/current/schema-registry/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kafka schema registry"),s("OutboundLink")],1),t._v(".")],1),t._v(" "),s("p",[t._v("This is just the beginning for this plugins but plan to support Json schema & Protobuf with schema registry. Also, as we said before, we want to support a "),s("code",[t._v("Consume")]),t._v(" tasks (with ou without of consumer groups). Maybe also a "),s("RouterLink",{attrs:{to:"/docs/developer-guide/triggers/"}},[t._v("Trigger")]),t._v(" based on "),s("code",[t._v("Consume")]),t._v(" that allow you start executions based on incoming topic, we wait for more community feedback on this part.")],1),t._v(" "),s("h2",{attrs:{id:"singer-plugins"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#singer-plugins"}},[t._v("#")]),t._v(" Singer plugins")]),t._v(" "),s("p",[t._v("We made an evolution on how "),s("RouterLink",{attrs:{to:"/plugins/plugin-singer/"}},[t._v("singer plugins")]),t._v(". Singer have 2 concepts: taps (source of data) and targets (destination, where you load data). This pattern is smart since you can have a lot of different sources that can be load on as many destinations that you need thanks to "),s("a",{attrs:{href:"https://github.com/singer-io/getting-started/blob/master/docs/SPEC.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("singer specifications"),s("OutboundLink")],1),t._v(".")],1),t._v(" "),s("p",[t._v("Before the plugins have a single task target that embed a tap that allow you to load from a source to 1 destination only. Now we have 2 different tasks that allow you to download 1 time from a tap and send the same result to many destinations.")]),t._v(" "),s("p",[t._v("Here is an example loading "),s("RouterLink",{attrs:{to:"/plugins/plugin-singer/tasks/taps/io.kestra.plugin.singer.taps.GitHub.html"}},[t._v("GitHub")]),t._v(" from a repository to a "),s("RouterLink",{attrs:{to:"/plugins/plugin-singer/tasks/targets/io.kestra.plugin.singer.targets.AdswerveBigQuery.html"}},[t._v("BigQuery Dataset")]),t._v(":")],1),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tasks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" github\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" io.kestra.plugin.singer.taps.GitHub\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("accessToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ vars.github.token }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("repositories")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" kestra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("io/kestra\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("startDate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2019-07-01"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("raw")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("streamsConfigurations")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replicationMethod")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" INCREMENTAL\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("selected")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("selected")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" projects\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("selected")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" project_cards\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("selected")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" project_columns\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("runner")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" DOCKER\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("dockerOptions")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("image")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" python"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.8")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" bigquery\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" io.kestra.plugin.singer.targets.AdswerveBigQuery\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("addMetadataColumns")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("from")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ outputs.github.raw }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("datasetId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" github\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("location")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" EU\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("projectId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{vars.serviceAccount}}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("serviceAccount")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{vars.projectId}}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("runner")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" DOCKER\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("dockerOptions")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("image")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" python"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.8")]),t._v("\n")])])]),s("p",[t._v("But you can still use Kestra internal storage with any singer taps and use the data with any Kestra tasks:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" github\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# same as above")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("raw")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" update\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"io.kestra.plugin.jdbc.sqlserver.Batch"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" jdbc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("sqlserver"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//localhost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("41433;trustServerCertificate=true\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("username")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sa\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("password")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Sqls3rv3r_Pa55word"),s("span",{pre:!0,attrs:{class:"token tag"}},[t._v("!")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("from")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ outputs.github.streams.commit }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sql")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into commit values( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )"')]),t._v("\n\n\n")])])]),s("p",[t._v("We also add another singer destination "),s("RouterLink",{attrs:{to:"/plugins/plugin-singer/tasks/taps/io.kestra.plugin.singer.taps.PipelinewiseOracle.html"}},[t._v("Oracle")]),t._v(".")],1),t._v(" "),s("h2",{attrs:{id:"gcp"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#gcp"}},[t._v("#")]),t._v(" GCP")]),t._v(" "),s("h3",{attrs:{id:"vertex-ai-custom-job"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#vertex-ai-custom-job"}},[t._v("#")]),t._v(" Vertex AI Custom Job")]),t._v(" "),s("p",[s("a",{attrs:{href:"https://cloud.google.com/vertex-ai",target:"_blank",rel:"noopener noreferrer"}},[t._v("VertexAI"),s("OutboundLink")],1),t._v(" is a full suite for Machine Learning allowing you to build, deploy, and scale ML models faster.")]),t._v(" "),s("p",[t._v("We have added a tasks "),s("RouterLink",{attrs:{to:"/plugins/plugin-gcp/tasks/vertexai/io.kestra.plugin.gcp.vertexai.CustomJob.html"}},[t._v("CustomJob")]),t._v(" that Start a Vertex AI "),s("a",{attrs:{href:"https://cloud.google.com/vertex-ai/docs/training/create-custom-job",target:"_blank",rel:"noopener noreferrer"}},[t._v("custom job"),s("OutboundLink")],1),t._v(". This one is based on a docker image that you can launch on any instance type, with or without GPU. It enables any kinds of custom code to deployed in order to be run in an ephemeral clusters and will be stop at the end of job. Perfect for large training of machine learning, but it can be any docker image that need to a large compute engine without having to create Kubernetes cluster or Compute engine.")],1),t._v(" "),s("p",[t._v("The integration will start the vertex job and will wait till the end of the job in order to transmit the status of the job to Kestra. We had made a deep integration, so you will also received logs in realtime for your running jobs.")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tasks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tableAnalysis\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" io.kestra.plugin.gcp.vertexai.CustomJob\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("delete")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("displayName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ task.id }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("projectId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{vars.serviceAccount}}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("serviceAccount")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{vars.projectId}}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("region")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" europe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("west1\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spec")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("serviceAccount")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" service"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("account"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("name@project"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("name.iam.gserviceaccount.com\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("workerPoolSpecs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerSpec")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("args")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-e"')]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ globals.env }}"')]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("commands")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" /app/start.sh\n            "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("imageUri")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{vars.imageUri}}"')]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("machineSpec")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("machineType")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" n1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("standard"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replicaCount")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"bigquery-retry"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bigquery-retry"}},[t._v("#")]),t._v(" BigQuery retry")]),t._v(" "),s("p",[t._v("We also have improved the retry on All BigQuery tasks. By default, we retry all operations with an internal errors for Google servers, but also "),s("RouterLink",{attrs:{to:"/plugins/plugin-gcp/tasks/bigquery/io.kestra.plugin.gcp.bigquery.Query.html#retrymessages"}},[t._v("some errors")]),t._v(" that could happen in real life: "),s("code",[t._v("rateLimitExceeded")]),t._v(", "),s("code",[t._v("due to concurrent update")]),t._v(", ... are many cases that a simple retry will make the tasks success. So we enable it by default. On a large BigQuery usage like the Leroy Merlin, this avoids unexpected failure that a simple retry could solve.")],1),t._v(" "),s("p",[t._v("Now, we must catch all errors on BigQuery that can be retried.")]),t._v(" "),s("h2",{attrs:{id:"flow-dependencies-in-entreprise-edition"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#flow-dependencies-in-entreprise-edition"}},[t._v("#")]),t._v(" Flow dependencies in Entreprise edition")]),t._v(" "),s("p",[t._v("For the entreprise edition, we have delivered the most wanted features: ability to see all flow dependencies recursively.")]),t._v(" "),s("video",{attrs:{controls:"true",allowfullscreen:"true"}},[s("source",{attrs:{src:a(559),type:"video/mp4"}})]),t._v(" "),s("p",[t._v("We also have added a confirmation when deleting a flow that have a dependencies, that warn user that the deletion could break the whole production plan.")]),t._v(" "),s("p",{staticClass:"text-center"},[s("img",{staticClass:"rounded img-thumbnail",attrs:{src:a(560),alt:"Kestra user interface"}})]),t._v(" "),s("div",{staticClass:"clearfix"}),t._v(" "),s("p",[t._v("This is high value feature that enable to have a full vision on all your data pipeline across teams. With many one consuming data from others one, no one can be sure if this flow changed, no others flow will be impacted. Impact analysis is greatly simplify thanks to this strong ui.")])])}),[],!1,null,null,null);e.default=n.exports}}]);