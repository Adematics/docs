(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{597:function(t,e,a){t.exports=a.p+"assets/img/executor-cpu-before.82fa6c91.png"},598:function(t,e,a){t.exports=a.p+"assets/img/executor-cpu-after.f9cc51de.png"},599:function(t,e,a){t.exports=a.p+"assets/img/lag-before.8249164c.png"},600:function(t,e,a){t.exports=a.p+"assets/img/lag-after.bbf4e884.png"},601:function(t,e,a){t.exports=a.p+"assets/img/queue-before.3153f882.png"},602:function(t,e,a){t.exports=a.p+"assets/img/queue-after.77035928.png"},603:function(t,e,a){t.exports=a.p+"assets/img/executor-duration-before.5f06143d.png"},604:function(t,e,a){t.exports=a.p+"assets/img/executor-duration-after.2798da95.png"},605:function(t,e,a){t.exports=a.p+"assets/media/deps.b59b5e10.mp4"},606:function(t,e,a){t.exports=a.p+"assets/img/deps.90668f87.png"},678:function(t,e,a){"use strict";a.r(e);var s=a(19),r=Object(s.a)({},(function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("p",[t._v("Since our "),s("a",{attrs:{href:"./2022-02-01-kestra-opensource"}},[t._v("public launch")]),t._v(", we've done a lot of work to give you the best possible experience, something we hope you will come to expect from Kestra. This latest release brings performance improvements to provide a smooth experience with large clusters, as well as some other great features.")]),t._v(" "),s("h2",{attrs:{id:"performance-for-large-clusters"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#performance-for-large-clusters"}},[t._v("#")]),t._v(" Performance for large clusters")]),t._v(" "),s("p",[t._v("Since we already have a "),s("a",{attrs:{href:"./2022-02-22-leroy-merlin-usage-kestra"}},[t._v("large deployment")]),t._v(" at Leroy Merlin, we have often encountered performance issues, but this one was more complicated to find. Here, we'll outline some metrics based on our large deployment on "),s("a",{attrs:{href:"./2022-02-22-leroy-merlin-usage-kestra"}},[t._v("Leroy Merlin")]),t._v("'s production environment and show you some before and after graphs for the same workload. Leroy Merlin's usage is mostly processed overnight, with all flows starting simultaneously around 3AM with 4000+ executions and 40,000+ tasks.")]),t._v(" "),s("p",[t._v("We have done a lot of work to "),s("strong",[t._v("reduce CPU usage and latency")]),t._v(".")]),t._v(" "),s("p",[t._v("As you can see, the same workload previously used 3 executors (we used autoscaling), with a total usage of 2.5 cores for over 6 hours."),s("br"),t._v("\nAfter, only "),s("strong",[t._v("0.5 cores")]),t._v(" were necessary through most of the runtime, with a peak of only 1.5 cores for 1 hour, the whole workload was managed by only 2 executors (minimum autoscaling).")]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(597),alt:"before"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("Before")])]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(598),alt:"after"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("After")])]),t._v(" "),s("p",[t._v("On the Kafka side, we also see "),s("strong",[t._v("improved latency")]),t._v("."),s("br"),t._v("\nThe system had a lot of "),s("RouterLink",{attrs:{to:"/docs/developer-guide/triggers/flow.html"}},[t._v("flow triggers")]),t._v(", which needed to be analyzed for each completed execution. When you have a high volume of execution, a lot of messages are sent by Kafka and if your consumer is too slow, the queue fills up and increases latency."),s("br"),t._v("\nPreviously, we had a large message lag that led to a late start of flow executions (a few minutes). The optimization allowed us to keep the start of the flow to within a few seconds.")],1),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(599),alt:"before"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("Before")])]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(600),alt:"after"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("After")])]),t._v(" "),s("p",[t._v("The last graph shows the delay between the creation of the task and the task launched by the worker. Since we have optimized Kafka processing globally, we avoid queuing messages on Kafka and reduce the delay between task creation and worker processing.")]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(601),alt:"before"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("Before")])]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(602),alt:"after"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("After")])]),t._v(" "),s("p",[t._v("All of these improvements also provide a "),s("strong",[t._v("significant reduction in total execution time")]),t._v(". As all messages are consumed quickly, the time between each task is reduced and the total runtime is reduced.")]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(603),alt:"before"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("Before")])]),t._v(" "),s("figure",{staticClass:"figure",staticStyle:{width:"48%"}},[s("img",{staticClass:"figure-img img-fluid rounded",attrs:{src:a(604),alt:"after"}}),t._v(" "),s("figcaption",{staticClass:"figure-caption text-center"},[t._v("After")])]),t._v(" "),s("p",[t._v("Keep in mind that Leroy Merlin's workflow is unbalanced, and all executions take place at the same time, more than 3000 executions and more than 35,000 tasks in a short period of time, making up 50% of the entire day's workload. We have to provide the same requirement for night processing, even if we are all asleep."),s("br"),t._v("\nWe have more optimizations pending, but this provided a big improvement that will allow us to handle more complex clusters with lots of streams and concurrent executions. A full blog post is coming soon to expose what we discovered while scaling a "),s("a",{attrs:{href:"https://kafka.apache.org/documentation/streams/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kafka Streams"),s("OutboundLink")],1),t._v(" application.")]),t._v(" "),s("h2",{attrs:{id:"resilience"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#resilience"}},[t._v("#")]),t._v(" Resilience")]),t._v(" "),s("h2",{attrs:{id:"new-plugins-improvement"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#new-plugins-improvement"}},[t._v("#")]),t._v(" New plugins & improvement")]),t._v(" "),s("h3",{attrs:{id:"jdbc-plugins"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#jdbc-plugins"}},[t._v("#")]),t._v(" JDBC plugins")]),t._v(" "),s("h4",{attrs:{id:"batch-query"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#batch-query"}},[t._v("#")]),t._v(" Batch query")]),t._v(" "),s("p",[t._v("JDBC plugins have been given a major update that allows for bulk queries. This update allows you to use any file generated by Kestra storage to generate a batch query."),s("br"),t._v("\nYou can now read data from any task and generate a batch query to insert or update data in most JDBC databases.")]),t._v(" "),s("p",[t._v("Here is an example:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tasks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" query\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"io.kestra.plugin.jdbc.mysql.Query"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" jdbc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("mysql"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//127.0.0.1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("56982/\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("username")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" mysql_user\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("password")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" mysql_passwd\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sql")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" select * from users\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("store")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" load\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"io.kestra.plugin.jdbc.sqlserver.Batch"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" jdbc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("sqlserver"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//localhost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("41433;trustServerCertificate=true\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("username")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sa\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("password")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Sqls3rv3r_Pa55word"),s("span",{pre:!0,attrs:{class:"token tag"}},[t._v("!")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("from")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ inputs.query.uri }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sql")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into users values( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )"')]),t._v("\n")])])]),s("p",[t._v("In this example, we read a table from a mysql database using a "),s("RouterLink",{attrs:{to:"/plugins/plugin-jdbc-mysql/tasks/io.kestra.plugin.jdbc.mysql.Query.html"}},[t._v("Query")]),t._v("  and store it on internal storage, after generating a "),s("RouterLink",{attrs:{to:"/plugins/plugin-jdbc-sqlserver/tasks/io.kestra.plugin.jdbc.sqlserver.Batch.html"}},[t._v("bulk insert")]),t._v(" that will load the resulting dataset into a Microsoft SQL Server database.")],1),t._v(" "),s("div",{staticClass:"custom-block success"},[s("p",{staticClass:"custom-block-title"},[t._v("Easily move data to jdbc")]),t._v(" "),s("p",[t._v("Since we rely on Kestra's internal storage, any task that produces Kestra internal storage, such as "),s("RouterLink",{attrs:{to:"/plugins/plugin-serdes/tasks/json/io.kestra.plugin.serdes.json.JsonReader.html"}},[t._v("JsonReader")]),t._v(", "),s("RouterLink",{attrs:{to:"/plugins/plugin-serdes/tasks/avro/io.kestra.plugin.serdes.avro.AvroReader.html"}},[t._v("AvroReader")]),t._v(", ... can be used as a source. You can now move data from any source and any format thanks to Kestra plugins.")],1)]),t._v(" "),s("h4",{attrs:{id:"new-jdbc-plugin"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#new-jdbc-plugin"}},[t._v("#")]),t._v(" New Jdbc plugin")]),t._v(" "),s("p",[t._v("We also introduced 2 new jdbc plugins:")]),t._v(" "),s("ul",[s("li",[s("RouterLink",{attrs:{to:"/plugins/plugin-jdbc-sqlserver/"}},[t._v("Microsoft SQL Server")])],1),t._v(" "),s("li",[s("RouterLink",{attrs:{to:"/plugins/plugin-jdbc-vectorwise/"}},[t._v("Actian Vectorwise")])],1)]),t._v(" "),s("p",[t._v("Both support Query and Batch queries, so you can imagine many more use cases.")]),t._v(" "),s("h2",{attrs:{id:"kafka"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#kafka"}},[t._v("#")]),t._v(" Kafka")]),t._v(" "),s("p",[t._v("The Kafka plugin is now also released with a first "),s("RouterLink",{attrs:{to:"/plugins/plugin-kafka/tasks/io.kestra.plugin.kafka.Produce.html"}},[t._v("Produce")]),t._v(" (Consume will come soon).  Like the other plugins (jdbc, json, csv, ...), the Kafka plugins rely on Kestra's internal storage, allowing you to send from any source to Kafka.")],1),t._v(" "),s("p",[t._v("We currently support "),s("RouterLink",{attrs:{to:"/plugins/plugin-kafka/tasks/io.kestra.plugin.kafka.Produce.html#valueserializer"}},[t._v("many types of serializers inside Kafka")]),t._v(", the most notable ones are "),s("code",[t._v("STRING")]),t._v(", "),s("code",[t._v("JSON")]),t._v(" & "),s("code",[t._v("AVRO")]),t._v(" with support for "),s("a",{attrs:{href:"https://docs.confluent.io/platform/current/schema-registry/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kafka schema registry"),s("OutboundLink")],1),t._v(".")],1),t._v(" "),s("p",[t._v("This is just the beginning for this plugin but we plan to support JSON and the Protobuf schema with the schema registry. Also, as mentioned before, we want to support "),s("code",[t._v("Consume")]),t._v(" tasks (with OU without of consumer groups). We may also want a "),s("RouterLink",{attrs:{to:"/docs/developer-guide/triggers/"}},[t._v("Trigger")]),t._v(" based on "),s("code",[t._v("Consume")]),t._v(" that allows you to start executions based on an incoming topic, we are waiting for more feedback from the community for this part.")],1),t._v(" "),s("h2",{attrs:{id:"singer-plugins"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#singer-plugins"}},[t._v("#")]),t._v(" Singer plugins")]),t._v(" "),s("p",[t._v("We have made an evolutionary improvement on our "),s("RouterLink",{attrs:{to:"/plugins/plugin-singer/"}},[t._v("Singer plugins")]),t._v(". Singer operates based on 2 concepts: taps (data source) and targets (destination, where you load the data). This model is smart, since you can work with many different sources, and each can be loaded to as many destinations as you need thanks to "),s("a",{attrs:{href:"https://github.com/singer-io/getting-started/blob/master/docs/SPEC.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("Singer specifications"),s("OutboundLink")],1),t._v(".")],1),t._v(" "),s("p",[t._v("Previously, plugins had a single target task that incorporated a tap to load from one source to a single destination. Now we have 2 different tasks that allow you to download one time from a tap and send the same result to multiple destinations.")]),t._v(" "),s("p",[t._v("Here is an example of loading "),s("RouterLink",{attrs:{to:"/plugins/plugin-singer/tasks/taps/io.kestra.plugin.singer.taps.GitHub.html"}},[t._v("GitHub")]),t._v(" from a repository to a "),s("RouterLink",{attrs:{to:"/plugins/plugin-singer/tasks/targets/io.kestra.plugin.singer.targets.AdswerveBigQuery.html"}},[t._v("BigQuery Dataset")]),t._v(":")],1),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tasks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" github\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" io.kestra.plugin.singer.taps.GitHub\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("accessToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ vars.github.token }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("repositories")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" kestra"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("io/kestra\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("startDate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2019-07-01"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("raw")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("streamsConfigurations")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replicationMethod")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" INCREMENTAL\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("selected")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("selected")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" projects\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("selected")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" project_cards\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("selected")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("stream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" project_columns\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("runner")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" DOCKER\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("dockerOptions")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("image")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" python"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.8")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" bigquery\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" io.kestra.plugin.singer.targets.AdswerveBigQuery\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("addMetadataColumns")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("from")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ outputs.github.raw }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("datasetId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" github\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("location")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" EU\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("projectId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ vars.serviceAccount }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("serviceAccount")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ vars.projectId }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("runner")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" DOCKER\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("dockerOptions")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("image")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" python"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.8")]),t._v("\n")])])]),s("p",[t._v("You can still use Kestra's internal storage with any singer taps and use the data with any Kestra tasks:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" github\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# same as above")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("raw")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" update\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"io.kestra.plugin.jdbc.sqlserver.Batch"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("url")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" jdbc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("sqlserver"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//localhost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("41433;trustServerCertificate=true\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("username")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sa\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("password")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Sqls3rv3r_Pa55word"),s("span",{pre:!0,attrs:{class:"token tag"}},[t._v("!")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("from")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ outputs.github.streams.commit }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sql")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into commit values( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )"')]),t._v("\n\n\n")])])]),s("p",[t._v("We also added another singer destination "),s("RouterLink",{attrs:{to:"/plugins/plugin-singer/tasks/taps/io.kestra.plugin.singer.taps.PipelinewiseOracle.html"}},[t._v("Oracle")]),t._v(".")],1),t._v(" "),s("h2",{attrs:{id:"gcp"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#gcp"}},[t._v("#")]),t._v(" GCP")]),t._v(" "),s("h3",{attrs:{id:"vertex-ai-custom-job"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#vertex-ai-custom-job"}},[t._v("#")]),t._v(" Vertex AI Custom Job")]),t._v(" "),s("p",[s("a",{attrs:{href:"https://cloud.google.com/vertex-ai",target:"_blank",rel:"noopener noreferrer"}},[t._v("VertexAI"),s("OutboundLink")],1),t._v(" is a complete suite for machine learning that allows you to build, deploy and scale ML models faster.")]),t._v(" "),s("p",[t._v("We've added a "),s("RouterLink",{attrs:{to:"/plugins/plugin-gcp/tasks/vertexai/io.kestra.plugin.gcp.vertexai.CustomJob.html"}},[t._v("CustomJob")]),t._v(" that starts a "),s("a",{attrs:{href:"https://cloud.google.com/vertex-ai/docs/training/create-custom-job",target:"_blank",rel:"noopener noreferrer"}},[t._v("Vertex AI Custom Job"),s("OutboundLink")],1),t._v(". This one is based on a docker image that you can launch on any type of instance, with or without a GPU. It allows you to deploy any kind of custom code to be run in ephemeral clusters and will be stopped when the job is finished. This is perfect for large-scale machine learning, but it can be used for any Docker image that requires a large compute engine without having to create a Kubernetes cluster or compute engine.")],1),t._v(" "),s("p",[t._v("The integration will start the vertex job and wait for the job to finish before passing the job status to Kestra. We have done a deep integration, so you will also receive real-time logs for your running jobs.")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tasks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tableAnalysis\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" io.kestra.plugin.gcp.vertexai.CustomJob\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("delete")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("displayName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ task.id }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("projectId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ vars.serviceAccount }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("serviceAccount")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ vars.projectId }}"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("region")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" europe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("west1\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spec")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("serviceAccount")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" service"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("account"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("name@project"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("name.iam.gserviceaccount.com\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("workerPoolSpecs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerSpec")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("args")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-e"')]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ globals.env }}"')]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("commands")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" /app/start.sh\n            "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("imageUri")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{{ vars.imageUri }}"')]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("machineSpec")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("machineType")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" n1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("standard"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replicaCount")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n")])])]),s("h3",{attrs:{id:"bigquery-retry"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bigquery-retry"}},[t._v("#")]),t._v(" BigQuery retry")]),t._v(" "),s("p",[t._v("We also improved the retry of all BigQuery tasks. By default, we retry all operations with an internal error for Google servers, but also "),s("RouterLink",{attrs:{to:"/plugins/plugin-gcp/tasks/bigquery/io.kestra.plugin.gcp.bigquery.Query.html#retrymessages"}},[t._v("some errors")]),t._v(" that could happen in real life, including: "),s("code",[t._v("rateLimitExceeded")]),t._v(", "),s("code",[t._v("due to concurrent update")]),t._v(", and more... These are many cases in which a simple retry will make the task successful. So we enable it by default. For a large use of BigQuery, such as our implementation at Leroy Merlin, this avoids unexpected failures that a simple retry could solve.")],1),t._v(" "),s("p",[t._v("Now we catch many errors automatically on BigQuery that can be retried.")]),t._v(" "),s("h2",{attrs:{id:"flow-dependencies-in-enterprise-edition"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#flow-dependencies-in-enterprise-edition"}},[t._v("#")]),t._v(" Flow dependencies in Enterprise Edition")]),t._v(" "),s("p",[t._v("For the Enterprise Edition, we delivered the most requested features: the ability to see all flow dependencies recursively.")]),t._v(" "),s("video",{attrs:{controls:"true",allowfullscreen:"true"}},[s("source",{attrs:{src:a(605),type:"video/mp4"}})]),t._v(" "),s("p",[t._v("We also added a confirmation when deleting a flow that has dependencies, which warns the user that deleting it might break the whole production plan.")]),t._v(" "),s("p",{staticClass:"text-center"},[s("img",{staticClass:"rounded img-thumbnail",attrs:{src:a(606),alt:"Kestra user interface"}})]),t._v(" "),s("div",{staticClass:"clearfix"}),t._v(" "),s("p",[t._v("This is a valuable feature that provides a complete view of your entire data pipeline across teams. With many teams consuming data from other teams, no one can be sure whether if this flow is changed, another flow will be impacted. Impact analysis is greatly simplified with this powerful user interface.")]),t._v(" "),s("h2",{attrs:{id:"conclusion"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[t._v("#")]),t._v(" Conclusion")]),t._v(" "),s("p",[t._v("In the meantime, we have released versions "),s("a",{attrs:{href:"https://github.com/kestra-io/kestra/releases/tag/v0.4.1",target:"_blank",rel:"noopener noreferrer"}},[t._v("0.4.1"),s("OutboundLink")],1),t._v(" and "),s("a",{attrs:{href:"https://github.com/kestra-io/kestra/releases/tag/v0.4.2",target:"_blank",rel:"noopener noreferrer"}},[t._v("0.4.2"),s("OutboundLink")],1),t._v(" to fix a few minor bugs and to provide some nice polish to our UX and UI.")]),t._v(" "),s("p",[t._v("We are working on the next step with a lot of new plugins allowing stronger integrations with the ecosystem."),s("br"),t._v("\nStay connected and follow us on "),s("a",{attrs:{href:"https://github.com/kestra-io/kestra",target:"_blank",rel:"noopener noreferrer"}},[t._v("GitHub"),s("OutboundLink")],1),t._v(", "),s("a",{attrs:{href:"https://twitter.com/kestra_io",target:"_blank",rel:"noopener noreferrer"}},[t._v("Twitter"),s("OutboundLink")],1),t._v(" or "),s("a",{attrs:{href:"https://join.slack.com/t/kestra-io/shared_invite/zt-193shv281-rK9QOEfZC2_vEbDO7Uxtbw",target:"_blank",rel:"noopener noreferrer"}},[t._v("Slack"),s("OutboundLink")],1),t._v(".")])])}),[],!1,null,null,null);e.default=r.exports}}]);