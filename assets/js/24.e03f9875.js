(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{556:function(e,t,a){e.exports=a.p+"assets/img/architecture.8b7d9920.svg"},645:function(e,t,a){"use strict";a.r(t);var r=a(19),s=Object(r.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"architecture"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#architecture"}},[e._v("#")]),e._v(" Architecture")]),e._v(" "),r("p",[r("img",{attrs:{src:a(556),alt:"Kestra Architecture",title:"Kestra Architecture"}})]),e._v(" "),r("h2",{attrs:{id:"dependencies"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#dependencies"}},[e._v("#")]),e._v(" Dependencies")]),e._v(" "),r("p",[e._v("At the heart, Kestra has a pluggable system allowing to switch some dependencies, but for now there is only one production environments architecture available :")]),e._v(" "),r("h3",{attrs:{id:"kafka"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#kafka"}},[e._v("#")]),e._v(" Kafka")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://kafka.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Kafka"),r("OutboundLink")],1),e._v(" is the real main dependency of Kestra, all the most important servers need to have a Kafka up & running. Kafka allows Kestra to be an infinitely scalable solution.")]),e._v(" "),r("h3",{attrs:{id:"elasticsearch"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch"}},[e._v("#")]),e._v(" ElasticSearch")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://www.elastic.co/",target:"_blank",rel:"noopener noreferrer"}},[e._v("ElasticSearch"),r("OutboundLink")],1),e._v(" is the database of Kestra, allowing displaying, searching, aggregating of all the data from Kestra (Flow, executions, ...)")]),e._v(" "),r("h3",{attrs:{id:"storage"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#storage"}},[e._v("#")]),e._v(" Storage")]),e._v(" "),r("p",[e._v("Kestra needs to store some files (incoming or outgoing files) and this notion is included in the heart of Kestra. Nowadays, storage availability is backup by many file systems, we rely on these to guarantee scalability of Kestra.")]),e._v(" "),r("p",[e._v("The storage is a simple plugin that you need to include and configure, by default only Local (not scalable) storage is available.")]),e._v(" "),r("p",[e._v("The storage used can be used by any Kestra servers except thee "),r("a",{attrs:{href:"#executor"}},[e._v("Executor")]),e._v(" & the "),r("a",{attrs:{href:"#indexer"}},[e._v("Indexer")]),e._v(" that don't need it.")]),e._v(" "),r("p",[e._v("Available storages are :")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"https://github.com/kestra-io/storage-minio",target:"_blank",rel:"noopener noreferrer"}},[e._v("Storage Minio"),r("OutboundLink")],1),e._v(" for "),r("a",{attrs:{href:"https://min.io/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Minio"),r("OutboundLink")],1),e._v(" compatible with "),r("a",{attrs:{href:"https://aws.amazon.com/s3/",target:"_blank",rel:"noopener noreferrer"}},[e._v("AWS S3"),r("OutboundLink")],1),e._v(" and all others "),r("em",[e._v("S3 Like")]),e._v(" storage")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://github.com/kestra-io/storage-gcs",target:"_blank",rel:"noopener noreferrer"}},[e._v("Storage GCS"),r("OutboundLink")],1),e._v(" for "),r("a",{attrs:{href:"https://cloud.google.com/storage",target:"_blank",rel:"noopener noreferrer"}},[e._v("Google Cloud Storage"),r("OutboundLink")],1)])]),e._v(" "),r("h2",{attrs:{id:"servers"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#servers"}},[e._v("#")]),e._v(" Servers")]),e._v(" "),r("p",[e._v("Kestra consist of multiple servers that can be scaled independently:")]),e._v(" "),r("h3",{attrs:{id:"executor"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#executor"}},[e._v("#")]),e._v(" Executor")]),e._v(" "),r("p",[e._v("Executors handle all executions and "),r("a",{attrs:{href:"../../developer-guide/flowable"}},[e._v("flowable tasks")]),e._v(". he only goal is to receive created execution and find what will be next tasks. There isn't (and can't) heavy computing on this part. Only looking at current execution and finding next tasks.")]),e._v(" "),r("p",[e._v("The executor also handles special execution cases:")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"../../developer-guide/listeners"}},[e._v("Listeners")])]),e._v(" "),r("li",[r("RouterLink",{attrs:{to:"/developer-guide/triggers/flow.html"}},[e._v("Flow Trigger")])],1),e._v(" "),r("li",[r("a",{attrs:{href:"../../developer-guide/templates"}},[e._v("Template")])])]),e._v(" "),r("p",[e._v("Internally, the executor is a heavy "),r("a",{attrs:{href:"https://kafka.apache.org/documentation/streams/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Kafka Stream"),r("OutboundLink")],1),e._v(". The executor processes all events coming from Kafka in the right order, keep an internal state of the execution and merge taskrun result coming from the worker."),r("br"),e._v("\nIt also detects a dead Worker and resubmits the task running by a dead worker.")]),e._v(" "),r("p",[e._v("Since the application is a Kafka Stream, the application can be scale infinitely (with the limit of partition count on Kafka) but since no heavy computation are done on the executor, this server doesn't use a lot of resources (except if you have a very high rate of execution)")]),e._v(" "),r("h3",{attrs:{id:"worker"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#worker"}},[e._v("#")]),e._v(" Worker")]),e._v(" "),r("p",[e._v("A worker is where the task is done. Worker will receive a task from Executor and will process it. Since tasks could be anything(heavy computation, simple api call, etc), worker is ThreadPool where you can configure the amount of thread you need.")]),e._v(" "),r("p",[e._v("Internally, workers are a simple "),r("a",{attrs:{href:"https://kafka.apache.org/documentation/#consumerapi",target:"_blank",rel:"noopener noreferrer"}},[e._v("Kafka Consumer"),r("OutboundLink")],1),e._v(" that will process any taskrun submitted. Worker will receive all tasks and dispatch internally in its Thread Pool."),r("br"),e._v("\nYou can also scale as you want workers and have many instances on multiple servers(with the limit of partition count on Kafka), each own with Thread Pool. If a worker is dead, the Executor will detect it and resubmit their current taskrun to another worker.")]),e._v(" "),r("h3",{attrs:{id:"scheduler"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#scheduler"}},[e._v("#")]),e._v(" Scheduler")]),e._v(" "),r("p",[e._v("Scheduler will handle most of the "),r("a",{attrs:{href:"../../developer-guide/triggers"}},[e._v("triggers")]),e._v(" (except the "),r("RouterLink",{attrs:{to:"/developer-guide/triggers/flow.html"}},[e._v("Flow Trigger handle by executor")]),e._v("). It will watch continuously all the triggers and detect if all the conditions are met to trigger an Execution (submitted to Executor).")],1),e._v(" "),r("p",[e._v("Internally, Scheduler has two ThreadPool :")]),e._v(" "),r("ul",[r("li",[r("strong",[e._v("ScheduledExecutorService")]),e._v(" : that will tick every second and try to find an available job")]),e._v(" "),r("li",[r("strong",[e._v("CachedThreadPool")]),e._v(" : that will compute in a separate Thread for all the trigger")])]),e._v(" "),r("div",{staticClass:"custom-block warning"},[r("p",{staticClass:"custom-block-title"},[e._v("WARNING")]),e._v(" "),r("p",[e._v("By default, Kestra will handle all date with your system timezone. You can change the timezone with "),r("a",{attrs:{href:"../administrator-guide/configuration/others#jvm-configuration"}},[e._v("JVM options")]),e._v(".")])]),e._v(" "),r("h3",{attrs:{id:"indexer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#indexer"}},[e._v("#")]),e._v(" Indexer")]),e._v(" "),r("p",[e._v("Indexer will watch for many Kafka topics and will simply copy the content to "),r("a",{attrs:{href:"#repositories"}},[e._v("Repositories")]),e._v(". This will save to ElasticSearch all the execution & flow allowing to have a rich ui.")]),e._v(" "),r("h3",{attrs:{id:"webserver"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#webserver"}},[e._v("#")]),e._v(" Webserver")]),e._v(" "),r("p",[e._v("Webserver will offer 2 main modules in the same server :")]),e._v(" "),r("ul",[r("li",[r("strong",[e._v("Api")]),e._v(": All the api allowing triggering execution for any systems, and to interact with Kestra.")]),e._v(" "),r("li",[r("strong",[e._v("Ui")]),e._v(": The ui is also served by the same webserver")])]),e._v(" "),r("p",[e._v("The webserver mostly interacts with Elasticsearch to have a rich api / ui. It also interacts with Kafka in order to trigger new execution, follow execution in real-time, ...")]),e._v(" "),r("div",{staticClass:"custom-block tip"},[r("p",{staticClass:"custom-block-title"},[e._v("TIP")]),e._v(" "),r("p",[e._v("As you understand, all the application is able to work only with Kafka and Storage (mostly except Scheduler). Elasticsearch is only available for the Web ui and if ElasticSearch is down, you can continue any workload on Kestra")])]),e._v(" "),r("h2",{attrs:{id:"plugins"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#plugins"}},[e._v("#")]),e._v(" Plugins")]),e._v(" "),r("p",[e._v("Kestra core doesn't allow to handle many tasks type. We have included a "),r("a",{attrs:{href:"../../plugins"}},[e._v("Plugins")]),e._v(" systems that allow you to develop as many tasks as you need."),r("br"),e._v("\nA wide range of plugins will be delivered by the Kestra team !")]),e._v(" "),r("h2",{attrs:{id:"repositories"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#repositories"}},[e._v("#")]),e._v(" Repositories")]),e._v(" "),r("p",[e._v("Repositories are the internal way to fetch data. On production servers, it will fetch data from ElasticSearch. There is a memory repository that is used during internal Kestra unit test and has an incomplete api. Never use this one on production")])])}),[],!1,null,null,null);t.default=s.exports}}]);